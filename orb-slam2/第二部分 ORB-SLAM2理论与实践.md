## ORB-SLAM2介绍
2015年，西班牙的萨拉戈萨大学机器人感知与实时研究组开源了ORB-SLAM第一个版本，ORB-SLAM出色的效果引起人们的广泛关注。
（1）名词术语。在继续介绍之前，我们有必要先简单介绍一些术语，如果初学者一时难以理解也没关系，我们在后面章节中会详细介绍，见表1。
表1 术语及含义

| 名词术语       | 含义                                                                                                                                                                                        |
| -------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 位姿           | 位置（平移）和姿态（旋转）的统称                                                                                                                                                            |
| Sim(3)变换     | 三维空间的相似变换群                                                                                                                                                                        |
| 关键帧         | 根据一定规则在连续几个普通帧中选取的最具代表性的一帧                                                                                                                                        |
| 特征点         | 按照人工设计的模式从图像上提取的二维像素点，可辨识度比较高                                                                                                                                  |
| 地图点         | 也称路标点，来自三维空间中物体表面的点。可以通过特征点匹配得到，也可以通过RGB-D、激光雷达等传感器直接测量得到                                                                               |
| 共视图         | 一种无向加权图，每个顶点都是关键帧。如果两个顶点之间满足一定的共视关系（共同观测到一定数量的地图点），则它们就会连成一条边，边的权重就是共视地图点的数目                                    |
| 本质图         | 共视图的简化版，保留共视图中所有的顶点，仅保留权重大于设定阈值的边                                                                                                                          |
| 生成树         | 本质图的简化版，仅保留本质图中具有父子关系的节点和边                                                                                                                                        |
| 尺度           | 单位的度量。纯单目视觉图像无法获得真实尺度，会被赋予一个相对的尺度；双目和RGB-D图像可以得到真实的尺度                                                                                       |
| 视觉单词       | 一般将特征点对应的描述子向量作为视觉单词                                                                                                                                                    |
| 视觉词袋       | 视觉单词的集合                                                                                                                                                                              |
| 视觉字典       | 由词袋组成的树称为视觉字典或视觉字典树                                                                                                                                                      |
| BA优化         | 用Bundle Adjustment 进行非线性优化                                                                                                                                                          |
| 地图初始化     | 生成最初的地图。使用单目相机进行地图初始化比较复杂，需要通过运动恢复结构的方式完成地图初始化。使用双目相机和RGB-D相机进行地图初始化则比较容易，可以直接将其第一帧对应的三维点作为初始化地图 |
| 参考关键帧跟踪 | 将当前普通帧（位姿未知）和它对应的参考关键帧（位姿已知）进行特征匹配及优化，从而估计当前普通帧的位姿                                                                                        |
| 恒速模型跟踪   | 两个图像帧之间一般只有几十毫秒的时间，假设在相邻帧间极短的时间内相机处于匀速运动状态，则可以用上一帧的位姿和速度估计当前帧的位姿                                                            |
| 重定位跟踪     | 当参考关键帧跟踪、恒速模型跟踪都失败时，通过词袋匹配，EPnP、反复的投影匹配和BA优化来找到丢失的位姿                                                                                          |
| 局部关键帧     | 满足一定共视关系的关键帧                                                                                                                                                                    |
| 局部地图点     | 满足一定共视关系的关键帧对应的地图点                                                                                                                                                        |
| 局部建图       | 一个独立的线程，输入是从跟踪线程传入的关键帧。目的是用共视关键帧及其地图点进行局部BA优化，让已有的关键帧之间产生更多的匹配，生成新的地图点，最终优化得到精确的位姿和地图点                  |
| 闭环           | 一个独立的线程，输入是从局部建图线程传入的关键帧。目的是判断机器人是否经过同一地点，一旦检测成功，即可进入全局优化，从而消除累计轨迹误差和地图误差                                          |
| 位置识别       | 用词袋匹配等方法判断两个场景是不是同一个地点                                                                                                                                                                                            |

（2）框架模块。ORB-SLAM2算法框架如图1所示，以下是对各个模块的说明。
![](https://cdn.jsdelivr.net/gh/liu-moon/pic@main/img/20230921152046.png)

![](https://cdn.jsdelivr.net/gh/liu-moon/pic@main/img/20230921151825.png)
- 输入。有3种输入模式可以选择：单目相机模式、双目相机模式和RGB-D相机模式。
- 跟踪线程：ORB-SLAM2地图初始化成功后，会分成两个阶段来跟踪。第一阶段跟踪的主要目的是“跟得上”，包括恒速模型跟踪、关键帧跟踪和重定位跟踪。首先会选择参考关键帧跟踪，在得到速度之后，后面主要使用的跟踪方式是恒速模型跟踪。当跟踪丢失时，启动重定位跟踪。在经过以上跟踪后，可以得到初始位姿。然后进入第二阶段跟踪——局部地图跟踪，目的是对位姿进一步优化。最后根据设定条件判断是否需要将当前帧创建为关键帧。
- 局部建图线程。输入的关键帧是跟踪线程种新建的关键帧。为了增加地图点的数目，在局部建图线程中共视关键帧之间会重新匹配特征，生成新的地图点。局部BA会同时优化共视图的关键帧位姿和地图点，优化后也会删除不准确的地图点和冗余的关键帧。
- 闭环线程。首先通过词袋查询关键帧数据库，找到和当前关键帧可能发生闭环的候选关键帧，然后求解它们之间的Sim(3)变换，最后执行闭环矫正和本质图优化，使得所有关键帧的位姿更准确。
- 全局BA。优化地图中所有的关键帧及其地图点。
- 位置识别。利用离线训练好的视觉字典判断场景的相似性，主要应用于特征匹配、重定位和闭环检测。
- 地图。地图包括地图点、关键帧、关键帧之间根据共视地图点数目组成的共视图及根据父子关系组成的生成树


（3）优点和缺点。因为ORB-SLAM2具备功能全面、精度高、适合二次开发等特点，于是成为视觉SLAM领域的代表作，之后有大量的研究者基于此进行延申和拓展。
1）ORB-SLAM2的优点
- 支持单目相机、双目相机和RGB-D相机的完整SLAM方案，能够实现闭环检测和重新定位的功能。
- 支持轻量级仅定位模式，该模式不适用局部建图和闭环检测线程，用视觉里程计跟踪未建图区域，可以达到零漂移。
- 跟踪、局部建图、闭环和重定位等任务都采用相同的ORB特征点，使得系统内数据交互更高效、稳定可靠。
- ORB特征点具有旋转不变性、光照不变性和尺度不变性，匹配速度快，适合实时应用。无论是在室内使用的小型手持设备，还是在工厂环境使用的无人机和在城市里驾驶的汽车，该算法都能够在CPU上实时工作。
- 单目初始化和应用场景解耦，不管是平面场景还是非平面场景，都可以自动初始化，无须人工干预。
- 地图点和关键帧的创建比较宽松，但后续会被严格筛选，剔除冗余关键帧和误差大的地图点，增加建图过程的弹性，可以在大旋转、快速运动和纹理不足等恶劣情况下提高跟踪的鲁棒性。
- 采用共视图，使得跟踪和建图控制在局部共视区域，与全局地图大小无关，可以在大场景下运行。
- 使用本质图优化位姿实现闭环检测，耗时少、精度高。
- 相比直接法，特征点法可用于宽基线特征匹配，更适合对深度、精度要求较高的场景，如三维重建。
- 定位精度高，可达厘米级别，是特征点法SLAM的经典代表作品。
- 代码规范，可读性强，包含很多工程化技巧，适合二次开发和扩展。

2）ORB-SLAM2的缺点
- 相比直接法SLAM框架，ORB-SLAM2的特征提取部分比较耗时，运行速度没有直接发快
- 相比直接法SLAM框架，ORB-SLAM2在弱纹理、重复纹理和图像模糊场景下容易跟踪丢失
- ORB-SLAM2产生的定位地图比较稀疏，应用有限

## 变量命名规范
在源码讲解之前， 有必要先了解代码中常见变量命名规则。
以小写字母m（member的首字母）开头的变量表示类的成员变量。比如：
```c++
int mSensor;
int mTrackingState;
std::mutex mMutexMode;
```
对于某些复杂的数据类型，第2个字母，甚至第3个字母也有一定的意义，比如。
以mp开头的变量表示指针（pointer）型类成员变量。
```c++
Tracking* mpTracker;
LocalMapping* mpLocalMapper;
LoopClosing* mpLoopCloser;
Viewer* mpViewer;
```
以mb开头的变量表示布尔（bool）型类成员变量。
```c++
bool mbOnlyTracking;
```
以mv开头的变量表示向量（vector）型类成员变量。
```c++
std::vector<int> mvIniLastMatches;
std::vector<cv::Point3f> mvIniP3D;
```
以mpt开头的变量表示指针（pointer）型类成员变量，并且它是一个线程（thread）。
```c++
std::thread* mptLocalMapping;
std::thread* mptLoopClosing;
std::thread* mptViewer;
```
以ml开头的变量表示列表（list）型类成员变量。
以mlp开头的变量表示列表（list）型类成员变量，并且它的元素类型是指针（pointer）。
以mlb开头的变量表示列表（list）型类成员变量，并且它的元素类型是布尔（bool）。
```c++
list<double> mlFrameTimes;
list<bool> mlbLost;
list<cv::Mat> mlRelativeFramePoses;
list<KeyFrame*> mlpReferences;
```
